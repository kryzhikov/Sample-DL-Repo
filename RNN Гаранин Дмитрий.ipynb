{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXd4o-HZkHQN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRIVQmrukHQQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ссылки:\n",
    "* [Chris Olah's blog (LSTM/GRU)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [PyTorch tutorial - RNN for name classification](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)\n",
    "* [MNIST classification with RNN tutorial](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)\n",
    "* [Good tutorials about Torch sentiment](https://github.com/bentrevett/pytorch-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NltJUttHkHQR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-4oBp1MkHQS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiAC7p6JkHQT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$\\Large h_{i+1} = tanh(W_x \\cdot X_{i+1} + W_y \\cdot h_{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9hhj5mLkHQT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Рекурретные нейросети нужны для работы с **последовательными данными** произвольной длины. Они представляют собой абстрактные ячейки, у которых есть какая-то **память** (hidden state), которая обновляется после обработки очередной порции данных.\n",
    "\n",
    "Если в самом простом виде, то в рекуррентных сетках для одного входного вектора $x_{(t)}$ и одного слоя рекуррентной сети справедливо такое соотношение:\n",
    "\n",
    "$$y_{(t)} = \\phi (x_{(t)}^T \\cdot w_x + y_{(t-1)}^T \\cdot w_y + b)$$\n",
    "\n",
    "где \n",
    "* $x(t)$ — входной вектор на текущем шаге;\n",
    "* $y(t)$ — выходной вектор на текущем шаге;\n",
    "* $w_x$ — вектор весов нейронов для входа;\n",
    "* $w_y$ — вектор весов нейронов для выхода;\n",
    "* $y(t-1)$ — выходной вектор с прошлого шага (для первого шага этот вектор нулевой);\n",
    "* $b$ — bias;\n",
    "* $\\phi$ — какая-то функция активации (например, ReLU).\n",
    "\n",
    "Эту ячейку применяют по очереди ко всей последовательности, пробрасывая hidden state с предыдущего состояния. С точки зрения построения вычислительного графа это выглядит так:\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"600\">\n",
    "\n",
    "То есть если зафиксировать длину последовательности, то мы получим обычный фиксированный ациклический граф вычислений, в котором просто пошерены параметры всех ячеек.\n",
    "\n",
    "### Упрощение формулы\n",
    "\n",
    "Снова немножко математики чтобы привести формулу выше к более удобному виду.\n",
    "\n",
    "Представим, что на вход подается не один вектор $x_{(t)}$, а целый мини-батч размера $m$ таких векторов $X_{(t)}$, соответственно все дальнейшие размышления мы уже производим в матричном виде:\n",
    "\n",
    "$$ Y_{(t)} = \\phi(X_{(t)}^T \\cdot W_x + Y_{(t-1)}^T \\cdot W_y + b) = \\phi([X_{(t)} Y_{(t-1)}] \\cdot W + b) $$\n",
    "где\n",
    "$$ W = [W_x W_y]^T $$\n",
    "\n",
    "*Операция в квадратных скобках — конкатенация матриц\n",
    "\n",
    "По размерностям:\n",
    "* $Y_{(t)}$ — матрица [$m$ x n_neurons]\n",
    "* $X_{(t)}$ — матрица [$m$ x n_features]\n",
    "* $b$ — вектор длины n_neurons\n",
    "* $W_x$ — веса между входами и нейронами размерностью [n_features x n_neurons]\n",
    "* $W_y$ — веса связей с прошлым выходом размерностью [n_neurons x n_neurons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq6dnwWWkHQU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# RNN from scratch\n",
    "\n",
    "**Disclaimer:** не используйте самописные RNN-ки в реальной жизни.\n",
    "\n",
    "Давайте реализуем торчовый модуль, который это реализует."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSkcPzlokHQW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        # <создать Wx, Wy?>\n",
    "\n",
    "    def forward(self, input_data, hidden):\n",
    "        # <использовать Wx, Wy для полученния нового hidden>\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9n3gNkPkHQY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_feature_size = 6\n",
    "hidden_size=5\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rqMgLsqkHQd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=input_feature_size, hidden_size=hidden_size)\n",
    "initial_hidden = rnn.init_hidden(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZssjzwGDkHQg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_example = torch.rand([batch_size, input_feature_size])\n",
    "new_hidden = rnn(input_example, initial_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdiE8vn-kHQi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(new_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io1NEsIKkHQm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"initial_hidden: \", initial_hidden.numpy())\n",
    "print(\"new_hidden: \", new_hidden.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIwKBaQWkHQo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_hidden = rnn(input_example, new_hidden)\n",
    "print(\"new_hidden: \", new_hidden.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGdYtkjTkHQq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание**. Модифицируйте код так, чтобы на вход можно было подавать батчи размером больше 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGi7O7qekHQr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Классификация картинок с RNN\n",
    "\n",
    "Представьте, что у вас есть какая-то длинная картинка, в которой свёртки точно не зайдут. Например, снимки со спутника, спектрограмма или длиннокот."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0H9o53CkHQs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Можно обработать их построчно с помощью рекуррентных сетей — просто подавать в качестве входа все пиксели очередной строки.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*wFYZpxTTiXVqncOLQd_CIQ.jpeg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaQ0QhgfkHQt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmOhDZDEkHQv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ahhqfzgkHQw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# переводим все в тензоры\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zb3byVwpkHQz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls -lh data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVCuLHrmkHQ4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSBQfZBrkHQ8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Как выглядит классификация с RNN в общем виде "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTIzNZ09kHQ9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*vhAfRLlaeOXZ-bruv7Ostg.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZ2UZw8vkHQ-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FZWcJTokHRB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_STEPS = 28\n",
    "N_INPUTS = 28\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 10\n",
    "N_EPHOCS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLaGmqMnkHRE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "logits = model(images.view(-1, 28,28))\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snsRIyjtkHRJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDAvHQlTkHRK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model instance\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Flff1olHkHRN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(N_EPHOCS):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    # TRAINING ROUND\n",
    "    for i, data in enumerate(trainloader):\n",
    "         # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 28,28) \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "         \n",
    "    model.eval()\n",
    "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TPiwYZgkHRS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Смотрим что на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6j98n0YbkHRT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 28, 28)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "        \n",
    "print('Test Accuracy: %.2f'%( test_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM_LmfEWkHRV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Сентимент анализ\n",
    "\n",
    "Домашка — классифицировать отзывы с IMDB на положительный / отрицательный только по тексту.\n",
    "\n",
    "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment1.png\">\n",
    "\n",
    "Суть такая же, только нужно предобработать тексты — каждому слову сопоставить обучаемый вектор (embedding), который пойдёт дальше в RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260519,
     "status": "ok",
     "timestamp": 1653675158502,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "-jprChrLiWAh",
    "outputId": "705e1f4b-9ad9-4ccc-e7bc-420a200899fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchtext==0.9.0\n",
      "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 7.1 MB 5.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (1.21.6)\n",
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 735.5 MB 14 kB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9.0) (4.2.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
      "Installing collected packages: torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0+cu113\n",
      "    Uninstalling torch-1.11.0+cu113:\n",
      "      Successfully uninstalled torch-1.11.0+cu113\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.12.0\n",
      "    Uninstalling torchtext-0.12.0:\n",
      "      Successfully uninstalled torchtext-0.12.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\n",
      "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\u001B[0m\n",
      "Successfully installed torch-1.8.0 torchtext-0.9.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
      "\u001B[K     |█████████████▌                  | 834.1 MB 59.3 MB/s eta 0:00:20tcmalloc: large alloc 1147494400 bytes == 0x3a9b0000 @  0x7f20d4ffb615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001B[K     |█████████████████               | 1055.7 MB 1.3 MB/s eta 0:11:45tcmalloc: large alloc 1434370048 bytes == 0x7f006000 @  0x7f20d4ffb615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001B[K     |█████████████████████▋          | 1336.2 MB 1.3 MB/s eta 0:08:34tcmalloc: large alloc 1792966656 bytes == 0x3e38000 @  0x7f20d4ffb615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001B[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:03:59tcmalloc: large alloc 2241208320 bytes == 0x6ec20000 @  0x7f20d4ffb615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001B[K     |████████████████████████████████| 1982.2 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0xf4582000 @  0x7f20d4ffa1e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
      "tcmalloc: large alloc 2477817856 bytes == 0x16a7ee000 @  0x7f20d4ffb615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
      "\u001B[K     |████████████████████████████████| 1982.2 MB 5.2 kB/s \n",
      "\u001B[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 17.6 MB 24 kB/s \n",
      "\u001B[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (4.2.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.0\n",
      "    Uninstalling torch-1.8.0:\n",
      "      Successfully uninstalled torch-1.8.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0+cu113\n",
      "    Uninstalling torchvision-0.12.0+cu113:\n",
      "      Successfully uninstalled torchvision-0.12.0+cu113\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.11.0+cu113\n",
      "    Uninstalling torchaudio-0.11.0+cu113:\n",
      "      Successfully uninstalled torchaudio-0.11.0+cu113\n",
      "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 12.0 MB 4.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001B[38;5;2m✔ Linking successful\u001B[0m\n",
      "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# это уберет боль работы с текстами\n",
    "!pip install torchtext==0.9.0\n",
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQ0jIrMtkHRW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Примечание.** Torchtext уже не очень живой проект, а в spacy нет русского.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpiI5vjUkHRW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105725,
     "status": "ok",
     "timestamp": 1653675279178,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "MOCZ7pthkHRY",
    "outputId": "3bd47d23-7027-4938-a26a-44b743d0956c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 23.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1653675290027,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "KPHUYfw2kHRb",
    "outputId": "a8f19820-6189-4dea-a9c6-1dc40877ebed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total 1.7M\n",
      "-rw-r--r-- 1 7297 1000 882K Jun 11  2011 imdbEr.txt\n",
      "-rw-r--r-- 1 7297 1000 827K Apr 12  2011 imdb.vocab\n",
      "-rw-r--r-- 1 7297 1000 4.0K Jun 26  2011 README\n",
      "drwxr-xr-x 4 7297 1000 4.0K Apr 12  2011 \u001B[0m\u001B[01;34mtest\u001B[0m/\n",
      "drwxr-xr-x 5 7297 1000 4.0K Jun 26  2011 \u001B[01;34mtrain\u001B[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -lh data/imdb/aclImdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1653675291656,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "U3Ow6Q3okHRf",
    "outputId": "7ba03bd6-4680-4f77-de16-aac755a3ef56",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1653675293222,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "zQquyqCEkHRk",
    "outputId": "8061c354-837f-47d6-d837-4a32696ea5b9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'text': ['Well', ',', 'I', 'get', 'used', 'after', 'awhile', 'to', 'read', 'comments', 'about', 'these', 'movies', 'that', 'do', \"n't\", 'reflect', 'my', 'experience', 'at', 'all', '.', 'To', 'me', ',', 'Amitabh', 'was', 'a', 'better', 'villain', 'here', 'than', 'in', 'some', 'of', 'his', 'most', 'famous', 'movies', '.', 'He', 'was', 'a', 'die', '-', 'hard', 'villain', ',', 'a', 'no', '-', 'apologies', 'villain', '.', 'To', 'me', 'it', 'was', 'a', 'breath', 'of', 'fresh', 'air', 'to', 'see', 'him', 'in', 'a', 'role', 'where', 'his', 'villainy', 'is', \"n't\", 'sort', 'of', 'undercut', 'in', 'some', 'way.<br', '/><br', '/>The', 'kid', 'who', 'played', 'Aryan', 'was', 'probably', 'over', 'his', 'head', 'with', 'this', 'cast', '.', 'There', 'I', 'think', 'maybe', 'the', 'director', 'could', 'have', 'done', 'better', '.', 'But', ',', 'to', 'be', 'honest', ',', 'the', 'very', 'best', 'part', 'of', 'this', 'movie', 'was', 'Shernaz', 'Patel', '.', 'She', 'is', 'an', 'unsung', 'heroine', ',', 'a', 'true', 'veteran', 'thespian', 'who', 'is', 'overqualified', 'for', 'every', 'role', 'she', 'is', 'offered', '.', 'But', 'I', 'must', 'say', 'I', 'appreciated', 'her', 'contribution', 'greatly', 'as', 'she', 'played', 'Virendra', 'Sahi', \"'s\", 'wife', '.', 'She', 'may', 'be', 'given', 'little', 'to', 'do', ',', 'but', 'she', 'does', 'everything', 'with', 'total', 'conviction', '.', 'I', \"'m\", 'sure', 'she', 'sailed', 'right', 'over', 'the', 'heads', 'of', 'most', 'of', 'the', 'audience.<br', '/><br', '/>So', 'if', 'you', 'are', 'in', 'a', 'habit', 'for', 'settling', 'for', 'Bollywood', 'average', ',', 'you', 'wo', \"n't\", 'get', 'much', 'out', 'of', 'this', 'movie', '.', 'But', 'if', 'you', 'constantly', 'search', 'for', 'something', 'more', ',', 'then', 'this', 'might', 'give', 'you', 'some', 'of', 'what', 'you', \"'ve\", 'been', 'missing', '.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BufoUgSCkHRn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Сделаем еще eval\n",
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7amSe4ikHRp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Сделаем словарь\n",
    "TEXT.build_vocab(train_data, max_size=25000)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1653675297034,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "IWw3xa1gkHRr",
    "outputId": "6959d37e-104e-4f6e-9c70-db3fe455864a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1653675298065,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "Z-_ejTnFkHRx",
    "outputId": "b36fa540-74a4-4ff7-9cef-82d494833e67",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'freqs': Counter({'neg': 8810, 'pos': 8690}),\n",
       " 'itos': ['neg', 'pos'],\n",
       " 'stoi': defaultdict(None, {'neg': 0, 'pos': 1}),\n",
       " 'unk_index': None,\n",
       " 'vectors': None}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "vars(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhJ0nG7akHRz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Почему 25002, а не 25000?\n",
    "Потому что $<unk>$ и $<pad>$\n",
    "\n",
    "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment6.png\" width=\"160\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1653675299882,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "qxMRpe-hkHRz",
    "outputId": "e770e328-8772-43ad-d8a0-4707582381ba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('the', 202430), (',', 191792), ('.', 165320), ('and', 109607), ('a', 109014), ('of', 100748), ('to', 93626), ('is', 76016), ('in', 61048), ('I', 53704), ('it', 53544), ('that', 48912), ('\"', 44522), (\"'s\", 43156), ('this', 42289), ('-', 37313), ('/><br', 35570), ('was', 34867), ('as', 30528), ('with', 29774)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kPcwN6qkHR1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* stoi (string to int)\n",
    "* itos (int to string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1653675301480,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "fVf_llCokHR2",
    "outputId": "79ad5fd2-b058-4d62-e8fb-c1ab4bf41bd6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1653675302733,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     },
     "user_tz": -240
    },
    "id": "K430yfrfkHR3",
    "outputId": "15ab590b-7410-40d6-b827-ad320e3a005a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "defaultdict(None, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzyXSNLTkHR5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# собираем батчи так, чтобы в каждом батче были примеры наиболее похожей длины\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1NZqp-6kHR9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Делаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgP2m_x0kHR-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment7.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9OlXUAvkHR_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* В эмбеддер (emb = [torch.nn.Embedding(num_embeddings, embedding_dim)](https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding)) запихиваем тензор размерностью **[sentence length, batch size]**\n",
    "* Эмбеддер возвращает тензор размерностью **[sentence length, batch size, embedding dim]**\n",
    "* RNN (torch.nn.RNN(embedding_dim, hidden_dim)) возвращает 2 тензора, *output* размера [sentence length, batch size, hidden dim] и *hidden* размера [1, batch size, hidden dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8UZ2geh2PjE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrizbizOkHR_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        #text,shape = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded.shape = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output.shape = [sent len, batch size, hid dim]\n",
    "        #hidden.shape = [1, batch size, hid dim]\n",
    "        \n",
    "#         assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctEOkK-6kHSB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 2\n",
    "N_EPHOCS = 10\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfEW475r2VBb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3fRRZjl2YLK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVuY3iy42fDL",
    "outputId": "4203ef5c-4fc0-41e6-949d-7ec8893e47c8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1653675669074,
     "user_tz": -240,
     "elapsed": 165078,
     "user": {
      "displayName": "Дима Гаранин",
      "userId": "13912667241235995320"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:  0 | Loss: 0.6967 | Train Accuracy: 50.33\n",
      "Test Accuracy: 50.04\n",
      "Epoch:  1 | Loss: 0.6974 | Train Accuracy: 49.82\n",
      "Test Accuracy: 49.68\n",
      "Epoch:  2 | Loss: 0.6967 | Train Accuracy: 50.59\n",
      "Test Accuracy: 49.84\n",
      "Epoch:  3 | Loss: 0.6968 | Train Accuracy: 50.43\n",
      "Test Accuracy: 49.47\n",
      "Epoch:  4 | Loss: 0.6963 | Train Accuracy: 50.74\n",
      "Test Accuracy: 49.52\n",
      "Epoch:  5 | Loss: 0.6952 | Train Accuracy: 50.02\n",
      "Test Accuracy: 51.11\n",
      "Epoch:  6 | Loss: 0.6947 | Train Accuracy: 50.01\n",
      "Test Accuracy: 50.62\n",
      "Epoch:  7 | Loss: 0.6941 | Train Accuracy: 50.14\n",
      "Test Accuracy: 50.62\n",
      "Epoch:  8 | Loss: 0.6946 | Train Accuracy: 50.75\n",
      "Test Accuracy: 50.73\n",
      "Epoch:  9 | Loss: 0.6956 | Train Accuracy: 50.01\n",
      "Test Accuracy: 51.03\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPHOCS):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    # TRAINING ROUND\n",
    "    for batch in train_iterator:\n",
    "         # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "      \n",
    "\n",
    "\n",
    "        loss = criterion(predictions, batch.label.long())\n",
    "        acc = get_accuracy(predictions, batch.label.long(), BATCH_SIZE)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc +=  get_accuracy(predictions, batch.label.long(), BATCH_SIZE)\n",
    "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
    "          %(epoch, train_running_loss / len(train_iterator), train_acc/ len(train_iterator)))         \n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for  batch in  valid_iterator:\n",
    "      predictions = model(batch.text).squeeze(1)\n",
    "      acc = get_accuracy(predictions, batch.label.long(), BATCH_SIZE) \n",
    "    \n",
    "      test_acc += get_accuracy(predictions, batch.label.long(), BATCH_SIZE)\n",
    "        \n",
    "    print('Test Accuracy: %.2f'%( test_acc/len( valid_iterator)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hGdYtkjTkHQq"
   ],
   "name": "Копия блокнота \"RNN Гаранин Дмитрий.ipynb\"",
   "provenance": [
    {
     "file_id": "1jY2TIKKnaconixrrN77-hqiQbmBZ3moU",
     "timestamp": 1653675730531
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}