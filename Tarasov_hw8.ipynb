{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarasov_hw8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aW6M5cuYuAoZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(fname):\n",
        "    with open(fname, 'r',  encoding='utf-8') as f:\n",
        "        nums = f.read().splitlines()\n",
        "    data = pd.DataFrame(nums)\n",
        "    data[0] = data[0].map(lambda s: re.sub('[^а-яА-Я,. ]','', s))\n",
        "    data = data.replace('', np.NaN)\n",
        "    data.dropna(inplace=True)\n",
        "    s = data[0]\n",
        "    s = s + '.'\n",
        "    s = s.map(lambda s: s[0:-2] + '.' if s[-2:] in ['..', ' .'] else s)\n",
        "    #s = s.map(lambda s: s[0:-1] + ' .' if s[-1:] in ['.'] else s)\n",
        "    data[0] = s\n",
        "    data = data.replace('', np.NaN)\n",
        "    data.dropna(inplace=True)\n",
        "    data.reset_index(drop = True, inplace=True)\n",
        "    #data[0] = data[0].map(lambda s: np.array(s.split()))\n",
        "    #print(data.to_numpy().shape)\n",
        "    data = data.to_numpy()#.reshape(3138, -1)\n",
        "    data = np.concatenate(data)\n",
        "    return data\n",
        "data = create_dataset('harry.txt')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVhbF4NvnQnW",
        "outputId": "8e3533b4-4ba6-4268-9e44-59ce45c1ac85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Джоанн Роулинг.', 'Гарри Поттер и Волшебный камень.', 'Глава.',\n",
              "       ...,\n",
              "       'Гарри задержался, чтобы попрощаться с Роном и Гермионой. Увидимся летом.',\n",
              "       'Желаю тебе  эээ  хорошо провести каникулы, Гермиона неуверенно поглядела вслед дяде Вернону, шокированная его грубостью.',\n",
              "       'Постараюсь, ответил Гарри, и его друзья удивились, увидев, как по лицу мальчика расползается торжествующая улыбка, Они ведь не знают, что нам не позволяется колдовать дома. Мы с Дудли славно позабавимся этим летом.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, data):\n",
        "      self.alphabet = 'абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
        "      symbols = ' ,.'+ self.alphabet+self.alphabet.upper()\n",
        "      self.char2idx = {symbols[i]: i+10 for i in range(len(symbols))}\n",
        "      self.idx2char = {i: symbols[i-10] for i in range(10, 77)}\n",
        "      print(self.char2idx)\n",
        "      print(self.idx2char)\n",
        "    \n",
        "    def tokenize(self, sequence):\n",
        "        # выполните какой-то базовый препроцессинг\n",
        "        # например, оставьте только алфавит и пунктуацию\n",
        "        #print(sequence)\n",
        "        return [self.char2idx[char] for char in sequence]\n",
        "    \n",
        "    def detokenize(self, sequence):\n",
        "        return ''.join([self.idx2char[idx] for idx in sequence])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.char2idx)"
      ],
      "metadata": {
        "id": "E-MrcZcZuGYq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset:\n",
        "    def __init__(self, data_path):\n",
        "        # загрузите данные\n",
        "        data = create_dataset(data_path)\n",
        "\n",
        "        # обучите вокаб\n",
        "        self.vocab = Vocab(data)\n",
        "\n",
        "        data_idx = []\n",
        "        #for i in data:\n",
        "          #data_idx.append(self.vocab.tokenize(i))\n",
        "        #print(data_idx)\n",
        "        # разделите данные на отдельные сэмплы для обучения\n",
        "        # (просто список из сырых строк)\n",
        "        self.data = data\n",
        "        #return self.data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)  \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        maxlen = 150\n",
        "        sample = self.data[idx]\n",
        "        #print(sample)\n",
        "        sample = torch.LongTensor(self.vocab.tokenize(sample))\n",
        "        \n",
        "        if maxlen - len(sample) > 0:\n",
        "          sample = torch.concat((sample, torch.zeros(maxlen - len(sample))))\n",
        "        else:\n",
        "          sample = sample[:150]\n",
        "        #print(sample, sample.shape)\n",
        "        sample = torch.LongTensor([*sample, 0])\n",
        "        sample = sample.long()# сконвертируйте в LongTensor\n",
        "        target = torch.LongTensor([0, *sample[:-1]])# нужно предсказать эту же последовательность со сдвигом 1\n",
        "        #print(sample, sample.shape)\n",
        "        return sample, target"
      ],
      "metadata": {
        "id": "9OIWywOfuGk3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = TextDataset('harry.txt')\n",
        "#torch.LongTensor([0, *[1,2,3,4,5]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bRyk8-QgxDR",
        "outputId": "a648a32e-2523-41bf-f78e-63b249987292"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 10, ',': 11, '.': 12, 'а': 13, 'б': 14, 'в': 15, 'г': 16, 'д': 17, 'е': 18, 'ж': 19, 'з': 20, 'и': 21, 'й': 22, 'к': 23, 'л': 24, 'м': 25, 'н': 26, 'о': 27, 'п': 28, 'р': 29, 'с': 30, 'т': 31, 'у': 32, 'ф': 33, 'х': 34, 'ц': 35, 'ч': 36, 'ш': 37, 'щ': 38, 'ъ': 39, 'ы': 40, 'ь': 41, 'э': 42, 'ю': 43, 'я': 44, 'А': 45, 'Б': 46, 'В': 47, 'Г': 48, 'Д': 49, 'Е': 50, 'Ж': 51, 'З': 52, 'И': 53, 'Й': 54, 'К': 55, 'Л': 56, 'М': 57, 'Н': 58, 'О': 59, 'П': 60, 'Р': 61, 'С': 62, 'Т': 63, 'У': 64, 'Ф': 65, 'Х': 66, 'Ц': 67, 'Ч': 68, 'Ш': 69, 'Щ': 70, 'Ъ': 71, 'Ы': 72, 'Ь': 73, 'Э': 74, 'Ю': 75, 'Я': 76}\n",
            "{10: ' ', 11: ',', 12: '.', 13: 'а', 14: 'б', 15: 'в', 16: 'г', 17: 'д', 18: 'е', 19: 'ж', 20: 'з', 21: 'и', 22: 'й', 23: 'к', 24: 'л', 25: 'м', 26: 'н', 27: 'о', 28: 'п', 29: 'р', 30: 'с', 31: 'т', 32: 'у', 33: 'ф', 34: 'х', 35: 'ц', 36: 'ч', 37: 'ш', 38: 'щ', 39: 'ъ', 40: 'ы', 41: 'ь', 42: 'э', 43: 'ю', 44: 'я', 45: 'А', 46: 'Б', 47: 'В', 48: 'Г', 49: 'Д', 50: 'Е', 51: 'Ж', 52: 'З', 53: 'И', 54: 'Й', 55: 'К', 56: 'Л', 57: 'М', 58: 'Н', 59: 'О', 60: 'П', 61: 'Р', 62: 'С', 63: 'Т', 64: 'У', 65: 'Ф', 66: 'Х', 67: 'Ц', 68: 'Ч', 69: 'Ш', 70: 'Щ', 71: 'Ъ', 72: 'Ы', 73: 'Ь', 74: 'Э', 75: 'Ю', 76: 'Я'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(x) for x in text.data], bins=350)\n",
        "plt.title('Распределение числа слов в предложениях.')\n",
        "plt.xlabel('Число слов')\n",
        "plt.xlim((0, 300))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "D_SJTv3nuGuX",
        "outputId": "37939b2d-c665-410f-9f57-94e569d07a56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_len = 40  # предложения с меньшим количеством символов не будут рассматриваться\n",
        "max_len = 150 # предложения с большим количеством символов будут обрезаться\n",
        "#Разобьём на обучение и валидацию:"
      ],
      "metadata": {
        "id": "oat6H4-CuG90"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset('harry.txt')\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ROZg-ESuHIK",
        "outputId": "753cc20f-3d04-491b-8146-db7477e82594"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 10, ',': 11, '.': 12, 'а': 13, 'б': 14, 'в': 15, 'г': 16, 'д': 17, 'е': 18, 'ж': 19, 'з': 20, 'и': 21, 'й': 22, 'к': 23, 'л': 24, 'м': 25, 'н': 26, 'о': 27, 'п': 28, 'р': 29, 'с': 30, 'т': 31, 'у': 32, 'ф': 33, 'х': 34, 'ц': 35, 'ч': 36, 'ш': 37, 'щ': 38, 'ъ': 39, 'ы': 40, 'ь': 41, 'э': 42, 'ю': 43, 'я': 44, 'А': 45, 'Б': 46, 'В': 47, 'Г': 48, 'Д': 49, 'Е': 50, 'Ж': 51, 'З': 52, 'И': 53, 'Й': 54, 'К': 55, 'Л': 56, 'М': 57, 'Н': 58, 'О': 59, 'П': 60, 'Р': 61, 'С': 62, 'Т': 63, 'У': 64, 'Ф': 65, 'Х': 66, 'Ц': 67, 'Ч': 68, 'Ш': 69, 'Щ': 70, 'Ъ': 71, 'Ы': 72, 'Ь': 73, 'Э': 74, 'Ю': 75, 'Я': 76}\n",
            "{10: ' ', 11: ',', 12: '.', 13: 'а', 14: 'б', 15: 'в', 16: 'г', 17: 'д', 18: 'е', 19: 'ж', 20: 'з', 21: 'и', 22: 'й', 23: 'к', 24: 'л', 25: 'м', 26: 'н', 27: 'о', 28: 'п', 29: 'р', 30: 'с', 31: 'т', 32: 'у', 33: 'ф', 34: 'х', 35: 'ц', 36: 'ч', 37: 'ш', 38: 'щ', 39: 'ъ', 40: 'ы', 41: 'ь', 42: 'э', 43: 'ю', 44: 'я', 45: 'А', 46: 'Б', 47: 'В', 48: 'Г', 49: 'Д', 50: 'Е', 51: 'Ж', 52: 'З', 53: 'И', 54: 'Й', 55: 'К', 56: 'Л', 57: 'М', 58: 'Н', 59: 'О', 60: 'П', 61: 'Р', 62: 'С', 63: 'Т', 64: 'У', 65: 'Ф', 66: 'Х', 67: 'Ц', 68: 'Ч', 69: 'Ш', 70: 'Щ', 71: 'Ъ', 72: 'Ы', 73: 'Ь', 74: 'Э', 75: 'Ю', 76: 'Я'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout, tie_weights):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers, dropout=dropout)\n",
        "        self.decoder = nn.Linear(hidden_dim, 1)\n",
        "        self.soft = nn.Softmax()\n",
        "        \n",
        "        if tie_weights:\n",
        "            # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
        "            # https://arxiv.org/abs/1608.05859\n",
        "            assert hidden_dim == embedding_dim\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        #self.rnn_type = rnn_type\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.nlayers = num_layers\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        #print(input)\n",
        "        #input = torch.tensor(input)\n",
        "        emb = self.encoder(input)\n",
        "        #print(emb.shape, hidden.shape)\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        decoded = self.decoder(output.view(output.size(0), output.size(1), output.size(2)))\n",
        "        output = self.soft(decoded)\n",
        "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # начальный хидден должен быть нулевой\n",
        "        # (либо хоть какой-то константный для всего обучения)\n",
        "        return torch.zeros(1, 151, self.hidden_dim)"
      ],
      "metadata": {
        "id": "Q01xNQvuuHVT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "lr = 1e-3 \n",
        "batch_size = 64\n",
        "\n",
        "device = torch.device('cpu')\n",
        "\n",
        "print(len(dataset.vocab))\n",
        "model = LM(\n",
        "    vocab_size = 151,\n",
        "    embedding_dim = 128,\n",
        "    hidden_dim = 128,\n",
        "    num_layers = 1,\n",
        "    dropout = 0.1,\n",
        "    tie_weights= True\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test = DataLoader(test_set, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9m_ae_ruHmT",
        "outputId": "b6bd7e2f-b7d7-4f54-f91b-feae35a044e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(epochs):\n",
        "    for x, y in train:\n",
        "        model.train()    \n",
        "        model.zero_grad()\n",
        "        hidden = model.init_hidden(len(x))\n",
        "        output, hidden = model(x, hidden)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.2)\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUzxbKu8uH4S",
        "outputId": "5109bff7-f1dd-4538-d4d9-ea3763ebeee6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    }
  ]
}